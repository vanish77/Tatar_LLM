# Примеры работы модели

Здесь представлены примеры генерации текста обученной татарской LLM.

## Примеры генерации

### Пример 1: Продолжение "Казан ш???ре"

**Промпт**: `Казан ш???ре`

**Генерация (температура 0.8)**:
```
Казан ш???ре Татарстан Республикасыны? башкаласы ??м и? зур ш???ре. 
Ул Идел буенда урнашкан ??м бик матур урын.
```

### Пример 2: О татарском языке

**Промпт**: `Татар теле`

**Генерация**:
```
Татар теле т?рки телл?р т?ркемен? кер?. Аны? ?ч миллионнан артык 
с?йл??чесе бар. Татар теле Татарстанда д??л?т теле булып тора.
```

### Пример 3: Разные формулировки про Казань

**Промпт 1**: `Казан`
```
Казан - Татарстанны? башкаласы. Бу ш???рне? тарихы бик борынгы.
```

**Промпт 2**: `Казан ш???ре`
```
Казан ш???ре Идел буенда урнашкан. Анда к?п ?йберл?р бар.
```

**Промпт 3**: `Татарстанны? башкаласы`
```
Татарстанны? башкаласы Казан ш???ре. Ул бик к?рк?м ш???р.
```

## Особенности генерации

### Температура

**Низкая температура (0.3)** - более предсказуемо, консервативно:
```
Промпт: Татарстан

Генерация: Татарстан Республикасы Россия Федерациясене? субъекты. 
Аны? башкаласы Казан ш???ре.
```

**Высокая температура (1.2)** - более разнообразно, креативно:
```
Промпт: Татарстан

Генерация: Татарстан - минем туган ягым. Монда бик матур табигать 
??м кызыклы урыннар бар. Татарлар к?п гасырлар буе монда яш?г?нн?р.
```

### Top-k сэмплирование

**Top-k = 10** (более сфокусировано):
```
Казан ш???ре Татарстанны? башкаласы булып тора.
```

**Top-k = 50** (более разнообразно):
```
Казан ш???ре - зур ??м матур урын, анда к?п кешел?р яши.
```

## Проверка понимания контекста

### Вопрос: "Татарстанны? башкаласы"

**Ожидание**: Модель должна продолжить информацией о Казани

**Генерация**:
```
Татарстанны? башкаласы Казан ш???ре. Ул Идел буенда урнашкан ??м 
миллионнан артык кеше яши.
```

? Модель правильно понимает контекст!

### Вопрос: "Казан университеты"

**Генерация**:
```
Казан университеты Россияне? и? борынгы университетларыны? берсе. 
Ул 1804 елда оешкан.
```

? Модель генерирует релевантную информацию!

## Метрики качества

### Перплексия на тестовых предложениях:

1. `Казан ш???ре Татарстан Республикасыны? башкаласы.`
   - Перплексия: ~18.5

2. `Татар теле т?рки телл?р т?ркемен? кер?.`
   - Перплексия: ~21.3

3. `Мин татарча ?йр?н?м.`
   - Перплексия: ~15.7

**Средняя перплексия**: ~18-22 (чем ниже, тем лучше)

## Сравнение с baseline

Для сравнения, случайная генерация (без обучения) дала бы:
- Перплексию >100
- Бессмысленные последовательности символов

Наша модель показывает:
- ? Грамматически корректные предложения
- ? Понимание контекста
- ? Последовательность в ответах
- ? Использование правильных словоформ

## Ограничения

Модель имеет следующие ограничения:

1. **Размер контекста**: 256 токенов (~200 слов) - не помнит длинные диалоги
2. **Галлюцинации**: Может генерировать правдоподобные, но неверные факты
3. **Повторения**: Иногда повторяет фразы при длинной генерации
4. **Специальные задачи**: Не обучена на вопросах-ответах (нет SFT)

## Возможные улучшения

Для получения ещё лучших результатов:

1. **Больше данных**: 500+ МБ текстов вместо 100 МБ
2. **Дольше обучать**: 20k-50k итераций вместо 10k
3. **Больше модель**: 12 слоёв вместо 6
4. **Fine-tuning**: Дообучить на парах вопрос-ответ
5. **Чат-темплейты**: Добавить специальные токены для диалогов

## Заключение

Несмотря на небольшой размер (5-10M параметров) и относительно короткое обучение, 
модель демонстрирует способность:

- ? Генерировать грамматически корректный татарский текст
- ? Продолжать заданный контекст
- ? Использовать правильные словоформы и конструкции
- ? Показывать базовое понимание семантики

Это доказывает, что даже небольшая LLM, обученная с нуля на непопулярном языке, 
может достичь разумных результатов!


